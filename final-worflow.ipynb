{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import cv2\n",
    "import numpy as np\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/harsh/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-10-28 Python-3.10.12 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce GTX 1650 Ti, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n",
      "Downloading: \"https://github.com/ultralytics/yolov5/zipball/master\" to /home/harsh/.cache/torch/hub/master.zip\n",
      "YOLOv5 ðŸš€ 2023-10-28 Python-3.10.12 torch-1.12.1+cu113 CUDA:0 (NVIDIA GeForce GTX 1650 Ti, 4096MiB)\n",
      "\n",
      "Fusing layers... \n",
      "Model summary: 157 layers, 7015519 parameters, 0 gradients, 15.8 GFLOPs\n",
      "Adding AutoShape... \n"
     ]
    }
   ],
   "source": [
    "# loading bike detection model\n",
    "bike_model = torch.hub.load('ultralytics/yolov5', 'custom', path = 'bike-detection/fifty-epochs-model/weights/last.pt', force_reload = True)\n",
    "\n",
    "\n",
    "helmet_model = torch.hub.load('ultralytics/yolov5', 'custom', path = 'fifty-epochs-helmet-detection/weights/best.pt', force_reload = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(\"bike-detection/bike-detection-1/test/images/228_jpg.rf.dac05f5f3fc291a0adea9628a9bfc47a.jpg\")\n",
    "image = cv2.resize(image, (640, 640))\n",
    "image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "image 1/1: 640x640 2 bikess\n",
      "Speed: 6.6ms pre-process, 148.4ms inference, 6.5ms NMS per image at shape (1, 3, 640, 640)\n",
      "image 1/1: 640x640 (no detections)\n",
      "Speed: 5.6ms pre-process, 94.2ms inference, 1.1ms NMS per image at shape (1, 3, 640, 640)\n"
     ]
    }
   ],
   "source": [
    "results = bike_model(image)\n",
    "print(results)\n",
    "image = results.render()[0]\n",
    "\n",
    "helmet_results = helmet_model(image)\n",
    "print(helmet_results)\n",
    "\n",
    "\n",
    "image = helmet_results.render()[0]\n",
    "\n",
    "cv2.imshow(\"aasasas\", image)\n",
    "cv2.waitKey(0)\n",
    "# time.sleep(10)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import threading\n",
    "import queue\n",
    "\n",
    "\n",
    "def capture_frames():\n",
    "    while True:\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        # Store the frame in a queue\n",
    "        frame_queue.put(frame)\n",
    "\n",
    "cap = cv2.VideoCapture('inputs/video/clip.mp4')\n",
    "frame_queue = queue.Queue()\n",
    "\n",
    "# Start a separate thread for frame capture\n",
    "frame_capture_thread = threading.Thread(target=capture_frames)\n",
    "frame_capture_thread.start()\n",
    "\n",
    "while True:\n",
    "    # Try to get a frame from the queue (non-blocking)\n",
    "    frame = frame_queue.get()\n",
    "    if frame is not None:\n",
    "        # Process the frame (resize, predict, etc.)\n",
    "        frame = cv2.resize(frame, (640, 640))\n",
    "        results = bike_model(frame)\n",
    "\n",
    "        frame = results.render()[0]\n",
    "\n",
    "        results = helmet_model(frame)\n",
    "\n",
    "        # Access and process predictions as needed\n",
    "        predictions = results.xyxy[0]\n",
    "        for prediction in predictions:\n",
    "            x_min, y_min, x_max, y_max, confidence, class_label = prediction\n",
    "            # Perform actions on each bounding box\n",
    "\n",
    "        # Display the resulting frame with all predictions\n",
    "        annotated_frame = results.render()[0]\n",
    "        cv2.imshow('Frame', annotated_frame)\n",
    "\n",
    "        if cv2.waitKey(25) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "# Clean up and release resources\n",
    "frame_capture_thread.join()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
